{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f810e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3f874",
   "metadata": {},
   "source": [
    "#### Get train and test data from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78fe2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(csv_file,test_percent):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        results = []\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            words = line.split(',')\n",
    "            for i in range(len(words)):\n",
    "                words[i] = float(words[i])\n",
    "            results.append(words)\n",
    "    Data = np.array(results)   \n",
    "    \n",
    "    val_size = test_percent/100\n",
    "    # calculate the number of validation data rows\n",
    "    val_rows = int(val_size * Data.shape[0])\n",
    "\n",
    "\n",
    "    # split the data into train and validation sets\n",
    "    Data_train = Data[val_rows:]\n",
    "    Data_train=np.array(Data_train)\n",
    "    Data_Y_train = Data_train[:,0].astype(int)\n",
    "    Data_X_train = np.delete(Data_train, 0, axis = 1)\n",
    "    #\n",
    "    Data_val = Data[:val_rows]\n",
    "    Data_val=np.array(Data_val)\n",
    "    Data_Y_val = Data_val[:,0].astype(int)\n",
    "    Data_X_val = np.delete(Data_val, 0, axis = 1)\n",
    "    return Data_X_train,Data_Y_train,Data_X_val,Data_Y_val\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700d55a",
   "metadata": {},
   "source": [
    "### FLDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b616aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLDA(X, y, n_components=None):\n",
    "    classes = np.unique(y)\n",
    "    total_mean=np.mean(X)\n",
    "    if n_components is None:\n",
    "        n_components = len(classes) - 1\n",
    "\n",
    "    means = []\n",
    "    scatter = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for c in classes:\n",
    "        Xc = X[y == c]\n",
    "        means.append(np.mean(Xc, axis=0))\n",
    "        scatter += np.cov(Xc.T, ddof=1)\n",
    "\n",
    "    S_W = scatter / len(classes)\n",
    "    S_B = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for i, mean in enumerate(means):\n",
    "        n = X[y == classes[i]].shape[0]\n",
    "        mean = mean.reshape(-1, 1)\n",
    "        S_B += n * (mean - total_mean).dot((mean - total_mean).T)\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(np.linalg.pinv(S_W).dot(S_B))\n",
    "    #eigenvalues, eigenvectors=eigenvalues.real,eigenvectors.real\n",
    "    top_indices = np.argsort(eigenvalues)[::-1][:n_components]\n",
    "    top_eigenvectors = eigenvectors[:, top_indices]\n",
    "    X_lda = X.dot(top_eigenvectors)\n",
    "\n",
    "    return X_lda, top_eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee239c2",
   "metadata": {},
   "source": [
    "#### FLDA with nearest mean classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0f44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FLDA_classifier(X_train, y_train, X_test, n_components=None):\n",
    "    X_train_lda,eigenvectors = FLDA(X_train, y_train, n_components)\n",
    "    means = []\n",
    "    for c in np.unique(y_train):\n",
    "        means.append(np.mean(X_train_lda[y_train == c], axis=0))\n",
    "\n",
    "    X_test_lda = X_test.dot(eigenvectors)\n",
    "    y_pred = []\n",
    "    for x in X_test_lda:\n",
    "        distances = [np.linalg.norm(x - mean) for mean in means]\n",
    "        y_pred.append(np.argmin(distances))\n",
    "\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc47e32",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5b765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(predicted_labels, test_labels):\n",
    "    \n",
    "    # Accuracy\n",
    "    \n",
    "    Accuracy = 0\n",
    "    for i in range(len(test_labels)):\n",
    "        if predicted_labels[i] == test_labels[i]:\n",
    "            Accuracy += 1\n",
    "    Accuracy /= len(predicted_labels)\n",
    "    Accuracy *= 100\n",
    "    print('Classification Accuracy  on Test Data is: ', Accuracy, '\\n')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    classes=len(np.unique(test_labels))\n",
    "    ConfMatrix = np.zeros([classes, classes])\n",
    "    \n",
    "    for i in range(len(test_labels)):\n",
    "        ConfMatrix[test_labels[i] - 1, predicted_labels[i] - 1] += 1\n",
    "    print('Confusion Matrix is: \\n', ConfMatrix, '\\n')\n",
    "    \n",
    "    # Precision\n",
    "    \n",
    "    Precision = []\n",
    "    for i in range(classes):\n",
    "        Precision.append(ConfMatrix[i][i] / np.sum(ConfMatrix[:,i]))\n",
    "    \n",
    "    # Recall\n",
    "    \n",
    "    Recall = []\n",
    "    for i in range(classes):\n",
    "        Recall.append(ConfMatrix[i][i] / np.sum(ConfMatrix[i,:]))\n",
    "    \n",
    "    # f1 Score\n",
    "    \n",
    "    f1Score = []\n",
    "    for i in range(classes):\n",
    "        f1Score.append(2 * Recall[i] * Precision[i] / (Recall[i] + Precision[i]))\n",
    "        print('f1 Score of Class ', i + 1 , ' is: ', f1Score[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9199965f",
   "metadata": {},
   "source": [
    "# A1_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d858c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(train_csv_file,test_csv_file):\n",
    "    with open(train_csv_file, 'r') as f:\n",
    "        results = []\n",
    "        for line in f:\n",
    "            words = line.split(',')\n",
    "            for i in range(len(words)):\n",
    "                words[i] = float(words[i])\n",
    "            results.append(words)\n",
    "    Data = np.array(results)\n",
    "    Data_Y_train=Data[:,10].astype(int)-1\n",
    "    Data_X_train = np.delete(Data, 10, axis = 1)\n",
    "    with open(test_csv_file, 'r') as f:\n",
    "        results = []\n",
    "        for line in f:\n",
    "            words = line.split(',')\n",
    "            for i in range(len(words)):\n",
    "                words[i] = float(words[i])\n",
    "            results.append(words)\n",
    "    Data_test = np.array(results)\n",
    "    Data_Y_test = Data_test[:,10].astype(int)-1\n",
    "    Data_X_test = np.delete(Data_test, 10, axis = 1)\n",
    "    return Data_X_train,Data_Y_train,Data_X_test,Data_Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb5207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X_train,Data_Y_train,Data_X_test,Data_Y_test=get_train_test('p3_train.csv','p3_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe800d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=FLDA_classifier(Data_X_train,Data_Y_train,Data_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe761213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for p3 in A1:\n",
      "Classification Accuracy  on Test Data is:  57.14666666666667 \n",
      "\n",
      "Confusion Matrix is: \n",
      " [[1700.  292.  269.  333.  387.]\n",
      " [ 317. 1866.  253.  290.  314.]\n",
      " [ 349.  256. 1727.  290.  353.]\n",
      " [ 326.  245.  334. 1774.  354.]\n",
      " [ 394.  303.  369.  400. 1505.]] \n",
      "\n",
      "f1 Score of Class  1  is:  0.5604087687489698\n",
      "f1 Score of Class  2  is:  0.6217927357547485\n",
      "f1 Score of Class  3  is:  0.582756875316349\n",
      "f1 Score of Class  4  is:  0.5797385620915034\n",
      "f1 Score of Class  5  is:  0.5115567641060503\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for p3 in A1:\")\n",
    "metrics(y_pred,Data_Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afec1eb",
   "metadata": {},
   "source": [
    "# A1_p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5adca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X_train,Data_Y_train,Data_X_test,Data_Y_test=get_train_test_split('p4_train.csv',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a97291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=FLDA_classifier(Data_X_train,Data_Y_train,Data_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62855ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for p4 in A1:\n",
      "Classification Accuracy  on Test Data is:  88.49444444444444 \n",
      "\n",
      "Confusion Matrix is: \n",
      " [[1742.    3.   13.   11.    9.    3.    0.    0.    6.   13.]\n",
      " [   3. 1712.   14.    2.   42.    0.    1.    1.    1.   24.]\n",
      " [   2.    0. 1478.  154.   50.    0.   53.    0.    0.   63.]\n",
      " [   1.    0.    7. 1730.   52.    0.    5.    0.    1.    4.]\n",
      " [   9.   11.   11.   67. 1684.    1.    3.   13.    1.    0.]\n",
      " [   3.    0.   67.   25.    3. 1547.  153.    0.    2.    0.]\n",
      " [  10.    0.  181.  137.   12.  302. 1130.    0.    3.   25.]\n",
      " [   6.    2.    3.   15.    6.    0.    0. 1669.   48.   51.]\n",
      " [   1.    0.    4.   76.    6.    9.   13.   40. 1642.    9.]\n",
      " [ 148.    1.   27.   12.    7.    2.    3.    3.    2. 1595.]] \n",
      "\n",
      "f1 Score of Class  1  is:  0.9353020134228188\n",
      "f1 Score of Class  2  is:  0.9702465287616889\n",
      "f1 Score of Class  3  is:  0.8199722607489597\n",
      "f1 Score of Class  4  is:  0.8587738893025565\n",
      "f1 Score of Class  5  is:  0.917461182239172\n",
      "f1 Score of Class  6  is:  0.8444323144104803\n",
      "f1 Score of Class  7  is:  0.7149636191078773\n",
      "f1 Score of Class  8  is:  0.9466817923993193\n",
      "f1 Score of Class  9  is:  0.9366799771819738\n",
      "f1 Score of Class  10  is:  0.8900669642857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for p4 in A1:\")\n",
    "metrics(y_pred,Data_Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab28cb",
   "metadata": {},
   "source": [
    "# <b>A1_p5</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da08db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_X_train,Data_Y_train,Data_X_val,Data_Y_val=get_train_test_split('PCA_MNIST.csv',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33cf439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=FLDA_classifier(Data_X_train,Data_Y_train,Data_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273fbf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for p5 in A1:\n",
      "Classification Accuracy  on Test Data is:  81.74444444444444 \n",
      "\n",
      "Confusion Matrix is: \n",
      " [[1642.    1.   62.    7.    4.    0.    1.   20.   21.   42.]\n",
      " [  21. 1557.   20.    1.  136.    0.   11.    2.    0.   52.]\n",
      " [   2.    2. 1473.  147.   28.    3.   75.    0.    2.   68.]\n",
      " [   0.    0.   22. 1703.   58.    3.    4.    4.    1.    5.]\n",
      " [   0.    7.   92.  107. 1580.    2.    5.    7.    0.    0.]\n",
      " [   0.    3.   48.   51.    4. 1169.  521.    0.    1.    3.]\n",
      " [  10.    0.  185.  203.    6.  311. 1053.    3.    2.   27.]\n",
      " [  10.    3.   10.   29.   19.    2.    1. 1586.   86.   54.]\n",
      " [   6.    0.   30.  114.    4.    6.   33.   61. 1512.   34.]\n",
      " [ 183.    0.   90.   21.   10.    0.    2.   36.   19. 1439.]] \n",
      "\n",
      "f1 Score of Class  1  is:  0.8938486663037561\n",
      "f1 Score of Class  2  is:  0.9232137563000297\n",
      "f1 Score of Class  3  is:  0.7687891440501045\n",
      "f1 Score of Class  4  is:  0.8142481472627301\n",
      "f1 Score of Class  5  is:  0.8659906823787339\n",
      "f1 Score of Class  6  is:  0.7093446601941747\n",
      "f1 Score of Class  7  is:  0.600684540787222\n",
      "f1 Score of Class  8  is:  0.9013924410343848\n",
      "f1 Score of Class  9  is:  0.8780487804878049\n",
      "f1 Score of Class  10  is:  0.8166855845629967\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics for p5 in A1:\")\n",
    "metrics(y_pred,Data_Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
